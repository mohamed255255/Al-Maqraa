{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers   import TensorBoardLogger\n",
    "\n",
    "\n",
    "from omegaconf import DictConfig\n",
    "from ruamel.yaml import YAML\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from nemo.utils.exp_manager import exp_manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'QuartzNet15x5', 'sample_rate': 16000, 'repeat': 1, 'dropout': 0.0, 'separable': True, 'labels': ['ا', 'إ', 'أ', 'آ', 'ء', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ؤ', 'ي', 'ئ', 'ى', 'ً', 'ࣰ', 'ٌ', 'ࣱ', 'ٍ', 'ࣲ', 'َ', 'ُ', 'ِ', 'ّ', 'ٓ', 'ۤ', 'ٔ', 'ۥ', 'ۧ', 'ۡ', 'ۨ', 'ٰ', '۠', '۟', '۪', 'ٱ', '۬', '۫', 'ۢ', 'ۭ', 'ۜ', 'ۣ', ' '], 'model': {'train_ds': {'manifest_filepath': 'training_subset.json', 'sample_rate': 16000, 'labels': ['ا', 'إ', 'أ', 'آ', 'ء', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ؤ', 'ي', 'ئ', 'ى', 'ً', 'ࣰ', 'ٌ', 'ࣱ', 'ٍ', 'ࣲ', 'َ', 'ُ', 'ِ', 'ّ', 'ٓ', 'ۤ', 'ٔ', 'ۥ', 'ۧ', 'ۡ', 'ۨ', 'ٰ', '۠', '۟', '۪', 'ٱ', '۬', '۫', 'ۢ', 'ۭ', 'ۜ', 'ۣ', ' '], 'batch_size': 32, 'normalize_transcripts': False, 'trim_silence': True, 'max_duration': 16.7, 'shuffle': True, 'num_workers': 0, 'pin_memory': True, 'is_tarred': False, 'tarred_audio_filepaths': None, 'shuffle_n': 2048, 'bucketing_strategy': 'synced_randomized', 'bucketing_batch_size': None}, 'validation_ds': {'manifest_filepath': 'testing_subset.json', 'sample_rate': 16000, 'labels': ['ا', 'إ', 'أ', 'آ', 'ء', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ؤ', 'ي', 'ئ', 'ى', 'ً', 'ࣰ', 'ٌ', 'ࣱ', 'ٍ', 'ࣲ', 'َ', 'ُ', 'ِ', 'ّ', 'ٓ', 'ۤ', 'ٔ', 'ۥ', 'ۧ', 'ۡ', 'ۨ', 'ٰ', '۠', '۟', '۪', 'ٱ', '۬', '۫', 'ۢ', 'ۭ', 'ۜ', 'ۣ', ' '], 'batch_size': 4, 'normalize_transcripts': False, 'shuffle': False, 'num_workers': 0, 'pin_memory': True}, 'preprocessor': {'_target_': 'nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor', 'normalize': 'per_feature', 'window_size': 0.02, 'sample_rate': 16000, 'window_stride': 0.01, 'window': 'hann', 'features': 64, 'n_fft': 512, 'frame_splicing': 1, 'dither': 1e-05, 'stft_conv': False}, 'spec_augment': {'_target_': 'nemo.collections.asr.modules.SpectrogramAugmentation', 'rect_freq': 50, 'rect_masks': 5, 'rect_time': 120}, 'encoder': {'_target_': 'nemo.collections.asr.modules.ConvASREncoder', 'feat_in': 64, 'activation': 'relu', 'conv_mask': True, 'jasper': [{'filters': 128, 'repeat': 1, 'kernel': [11], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True, 'separable': True, 'se': True, 'se_context_size': -1}, {'filters': 256, 'repeat': 1, 'kernel': [13], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True, 'separable': True, 'se': True, 'se_context_size': -1}, {'filters': 256, 'repeat': 1, 'kernel': [15], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True, 'separable': True, 'se': True, 'se_context_size': -1}, {'filters': 256, 'repeat': 1, 'kernel': [17], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True, 'separable': True, 'se': True, 'se_context_size': -1}, {'filters': 256, 'repeat': 1, 'kernel': [19], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True, 'separable': True, 'se': True, 'se_context_size': -1}, {'filters': 256, 'repeat': 1, 'kernel': [21], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': False, 'separable': True, 'se': True, 'se_context_size': -1}, {'filters': 1024, 'repeat': 1, 'kernel': [1], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': False, 'separable': True, 'se': True, 'se_context_size': -1}]}, 'decoder': {'_target_': 'nemo.collections.asr.modules.ConvASRDecoder', 'feat_in': 1024, 'num_classes': 64, 'vocabulary': ['ا', 'إ', 'أ', 'آ', 'ء', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ؤ', 'ي', 'ئ', 'ى', 'ً', 'ࣰ', 'ٌ', 'ࣱ', 'ٍ', 'ࣲ', 'َ', 'ُ', 'ِ', 'ّ', 'ٓ', 'ۤ', 'ٔ', 'ۥ', 'ۧ', 'ۡ', 'ۨ', 'ٰ', '۠', '۟', '۪', 'ٱ', '۬', '۫', 'ۢ', 'ۭ', 'ۜ', 'ۣ', ' ']}, 'optim': {'name': 'novograd', 'lr': 0.01, 'betas': [0.8, 0.5], 'weight_decay': 0.001, 'sched': {'name': 'CosineAnnealing', 'monitor': 'val_loss', 'reduce_on_plateau': False, 'warmup_steps': None, 'warmup_ratio': None, 'min_lr': 0.0, 'last_epoch': -1}}}, 'trainer': {'devices': 1, 'max_epochs': 5, 'max_steps': -1, 'num_nodes': 1, 'accelerator': 'gpu', 'strategy': 'ddp', 'accumulate_grad_batches': 1, 'enable_checkpointing': True, 'logger': True, 'log_every_n_steps': 1, 'val_check_interval': 1.0, 'benchmark': False}, 'exp_manager': {'exp_dir': 'checkpoint', 'name': 'my_experiment_name', 'create_tensorboard_logger': True, 'create_checkpoint_callback': False, 'resume_if_exists': True, 'resume_ignore_no_checkpoint': True, 'version': 0}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from ruamel.yaml import YAML\n",
    "except ModuleNotFoundError:\n",
    "    from ruamel_yaml import YAML\n",
    "config_path = './configs/config.yaml'\n",
    "yaml = YAML(typ='safe')\n",
    "with open(config_path) as f:\n",
    "    params = yaml.load(f)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-06 23:29:04 audio_to_text_dataset:45] Model level config does not contain `sample_rate`, please explicitly provide `sample_rate` to the dataloaders.\n",
      "[NeMo I 2024-07-06 23:29:04 audio_to_text_dataset:45] Model level config does not contain `labels`, please explicitly provide `labels` to the dataloaders.\n",
      "[NeMo I 2024-07-06 23:29:12 collections:196] Dataset loaded with 59966 files totalling 148.63 hours\n",
      "[NeMo I 2024-07-06 23:29:12 collections:197] 30034 files were filtered totalling 226.72 hours\n",
      "[NeMo I 2024-07-06 23:29:12 audio_to_text_dataset:45] Model level config does not contain `sample_rate`, please explicitly provide `sample_rate` to the dataloaders.\n",
      "[NeMo I 2024-07-06 23:29:12 audio_to_text_dataset:45] Model level config does not contain `labels`, please explicitly provide `labels` to the dataloaders.\n",
      "[NeMo I 2024-07-06 23:29:13 collections:196] Dataset loaded with 7500 files totalling 32.66 hours\n",
      "[NeMo I 2024-07-06 23:29:13 collections:197] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2024-07-06 23:29:13 features:289] PADDING: 16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  \n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_wer',  \n",
    "    mode='min',     \n",
    "    dirpath='checkpoints/', \n",
    "    filename='best_model-{epoch:02d}-{wer:.4f}',  \n",
    "    save_top_k=1,   \n",
    "    verbose=True,   \n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    devices=1, \n",
    "    accelerator='gpu', \n",
    "    max_epochs=100, \n",
    "    callbacks=[checkpoint_callback],  \n",
    "    logger = True\n",
    ")\n",
    "\n",
    "first_asr_model = nemo_asr.models.EncDecCTCModel(cfg=DictConfig(params['model']), trainer=trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncDecCTCModel(\n",
       "  (preprocessor): AudioToMelSpectrogramPreprocessor(\n",
       "    (featurizer): FilterbankFeatures()\n",
       "  )\n",
       "  (encoder): ConvASREncoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): JasperBlock(\n",
       "        (mconv): ModuleList(\n",
       "          (0): MaskedConv1d(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,), groups=64, bias=False)\n",
       "          )\n",
       "          (1): MaskedConv1d(\n",
       "            (conv): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm1d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): SqueezeExcite(\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=False)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=False)\n",
       "            )\n",
       "            (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "          )\n",
       "        )\n",
       "        (res): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): MaskedConv1d(\n",
       "              (conv): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "            (1): BatchNorm1d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (mout): Sequential(\n",
       "          (0): ReLU(inplace=True)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): JasperBlock(\n",
       "        (mconv): ModuleList(\n",
       "          (0): MaskedConv1d(\n",
       "            (conv): Conv1d(128, 128, kernel_size=(13,), stride=(1,), padding=(6,), groups=128, bias=False)\n",
       "          )\n",
       "          (1): MaskedConv1d(\n",
       "            (conv): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): SqueezeExcite(\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=False)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=False)\n",
       "            )\n",
       "            (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "          )\n",
       "        )\n",
       "        (res): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): MaskedConv1d(\n",
       "              (conv): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "            (1): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (mout): Sequential(\n",
       "          (0): ReLU(inplace=True)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): JasperBlock(\n",
       "        (mconv): ModuleList(\n",
       "          (0): MaskedConv1d(\n",
       "            (conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256, bias=False)\n",
       "          )\n",
       "          (1): MaskedConv1d(\n",
       "            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): SqueezeExcite(\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=False)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=False)\n",
       "            )\n",
       "            (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "          )\n",
       "        )\n",
       "        (res): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): MaskedConv1d(\n",
       "              (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "            (1): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (mout): Sequential(\n",
       "          (0): ReLU(inplace=True)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): JasperBlock(\n",
       "        (mconv): ModuleList(\n",
       "          (0): MaskedConv1d(\n",
       "            (conv): Conv1d(256, 256, kernel_size=(17,), stride=(1,), padding=(8,), groups=256, bias=False)\n",
       "          )\n",
       "          (1): MaskedConv1d(\n",
       "            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): SqueezeExcite(\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=False)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=False)\n",
       "            )\n",
       "            (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "          )\n",
       "        )\n",
       "        (res): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): MaskedConv1d(\n",
       "              (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "            (1): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (mout): Sequential(\n",
       "          (0): ReLU(inplace=True)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): JasperBlock(\n",
       "        (mconv): ModuleList(\n",
       "          (0): MaskedConv1d(\n",
       "            (conv): Conv1d(256, 256, kernel_size=(19,), stride=(1,), padding=(9,), groups=256, bias=False)\n",
       "          )\n",
       "          (1): MaskedConv1d(\n",
       "            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): SqueezeExcite(\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=False)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=False)\n",
       "            )\n",
       "            (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "          )\n",
       "        )\n",
       "        (res): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): MaskedConv1d(\n",
       "              (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "            (1): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (mout): Sequential(\n",
       "          (0): ReLU(inplace=True)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): JasperBlock(\n",
       "        (mconv): ModuleList(\n",
       "          (0): MaskedConv1d(\n",
       "            (conv): Conv1d(256, 256, kernel_size=(21,), stride=(1,), padding=(10,), groups=256, bias=False)\n",
       "          )\n",
       "          (1): MaskedConv1d(\n",
       "            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm1d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): SqueezeExcite(\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=False)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=False)\n",
       "            )\n",
       "            (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "          )\n",
       "        )\n",
       "        (mout): Sequential(\n",
       "          (0): ReLU(inplace=True)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): JasperBlock(\n",
       "        (mconv): ModuleList(\n",
       "          (0): MaskedConv1d(\n",
       "            (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,), groups=256, bias=False)\n",
       "          )\n",
       "          (1): MaskedConv1d(\n",
       "            (conv): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (2): BatchNorm1d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): SqueezeExcite(\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=1024, out_features=128, bias=False)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=128, out_features=1024, bias=False)\n",
       "            )\n",
       "            (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "          )\n",
       "        )\n",
       "        (mout): Sequential(\n",
       "          (0): ReLU(inplace=True)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ConvASRDecoder(\n",
       "    (decoder_layers): Sequential(\n",
       "      (0): Conv1d(1024, 65, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (loss): CTCLoss()\n",
       "  (spec_augmentation): SpectrogramAugmentation(\n",
       "    (spec_cutout): SpecCutout()\n",
       "  )\n",
       "  (_wer): WER()\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "checkpoint_path = './checkpoints/best_model-epoch=59-wer=0.0000.ckpt'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "first_asr_model.load_state_dict(checkpoint['state_dict'])\n",
    "first_asr_model.eval()\n",
    "\n",
    "\n",
    "\n",
    "# tensorboard --logdir=I:\\Almaqraa\\lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WER calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-06 23:29:13 audio_to_text_dataset:45] Model level config does not contain `sample_rate`, please explicitly provide `sample_rate` to the dataloaders.\n",
      "[NeMo I 2024-07-06 23:29:13 audio_to_text_dataset:45] Model level config does not contain `labels`, please explicitly provide `labels` to the dataloaders.\n",
      "[NeMo I 2024-07-06 23:29:14 collections:196] Dataset loaded with 7500 files totalling 32.66 hours\n",
      "[NeMo I 2024-07-06 23:29:14 collections:197] 0 files were filtered totalling 0.00 hours\n",
      "WER = 0.5319547621687548\n"
     ]
    }
   ],
   "source": [
    "params['model']['validation_ds']['batch_size'] = 8\n",
    "\n",
    "first_asr_model.setup_test_data(test_data_config=params['model']['validation_ds'])\n",
    "first_asr_model.cuda()\n",
    "first_asr_model.eval()\n",
    "\n",
    "\n",
    "wer_nums = []\n",
    "wer_denoms = []\n",
    "\n",
    "\n",
    "for test_batch in first_asr_model.test_dataloader():\n",
    "    test_batch = [x.cuda() for x in test_batch]\n",
    "    targets = test_batch[2]\n",
    "    targets_lengths = test_batch[3]\n",
    "    log_probs, encoded_len, greedy_predictions = first_asr_model(\n",
    "        input_signal=test_batch[0], input_signal_length=test_batch[1]\n",
    "    )\n",
    "\n",
    "    first_asr_model._wer.update(\n",
    "        predictions=greedy_predictions,\n",
    "        targets=targets,\n",
    "        target_lengths=targets_lengths,\n",
    "    )\n",
    "\n",
    "    _, wer_num, wer_denom = first_asr_model._wer.compute()\n",
    "    first_asr_model._wer.reset()\n",
    "    wer_nums.append(wer_num.detach().cpu().numpy())\n",
    "    wer_denoms.append(wer_denom.detach().cpu().numpy())\n",
    "\n",
    "    # Release tensors from GPU memory\n",
    "    del test_batch, log_probs, targets, targets_lengths, encoded_len, greedy_predictions\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"WER = {sum(wer_nums) / sum(wer_denoms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9992ac7eaa284914a03ef9417fa31e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['أُولَئِكَ عَلَى هُدًى مِن رَبِّهِم وَأُولَئِكَ هُمُ المُفلِحُونَ']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef1947c37f043e2990da8fffd128449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['اللَّيُ الصَّمَدِ']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff42dd534d3e4550bbb444920672a0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['وَلَقَد آتَينَا دَاوُودَ وَسُلَينَانَ حِلمً وَقَالَ الحَمدُلِلَّهِ الَّذِي فَضَّلَنَا عَلَى كَثِيرٍ مِن عِبَادِهِ المُؤمِنِينَ']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9532d6b5e749e78ccd2a8cdbbd2e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['فَبِأَيِّ آلَاءِ رَبِّكُمَا تُكَذِّبَانِ']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10eacec1298642f6910f75caf9ae6221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['كَاأَيُّنَا الَّذِينَ آمَنُو الكُرُو نِعمَتَ اللَّهِ عَلَيكُم إِذ َّاأَدتُم جُنُولُن فَأَرفَلنَا عَلَيهِ لِيحَوا وَجُنُودًاَم كَرَوذًا وَكَالَ اللَّهُ بِمَا تَعمَنُونَ بَطِيرًا']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d94f5ccbe8849aea0eaee4f5ad4f517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['يَا أَيُّهَا الَّذِينَ آمَنُوا إِذَا تَدَيَنتُم بِدَيهٍ إِلَى أَجَلٍ مُسَمَّ فَاككُرُوهُ وَليَكتُبَّينَكُم كَاتِ بُم بِالعَدل وَلَا يَأبَكَاتِ بٌ أَن يَك تُبَكَمَا عَلَّمَهُ اللَّهِ فَليَكتُّبوَليُملِلِ الَّذِي عَلَيهِ الحَقُّ وَليَتَّقِ الَّا هَرَبَّهُ وَلَا يَبخَس مِنهُ شَيئًا فَإِن كَانَ الَّذِي عَلَيهِ الحَقُّ سَفِينًا أَوضَعِيفًا أَولَا يَستَطِيعُ أَن يُمِ لَهُوَ فَ لُّم لِلوَلِيُّهُ بِالعَدِي وَاستَشِدُوا شَهِيدَينِ مِنرِّجَالِكُم فَإِن لَّم يَقُو نَارَجُلَينِ فَرَجُلُ وَامرَأَتَانِ مِنمَّن تَضَّونَ مِنَ الشُّ هَدًاءُ أَن تَضِلَّإِحدَاهُمَا فَُذَكِّرَ  إِحذَاهُمَا الأُخرَى وَلَا يَأبَششُّ هَدَاءُ إِذَا مَا دُوا وَلَا تَسأمُوا أَن تَكتُمُوهُ صَغِيرًا أَو كَبِيرًا إِلَى أَجَلِهِ ذَلِكُم أَقسَطُعِندَ اللَّهِ وَأَقوَمُلِالشَّهَادَِ وَأَدنَا أَلَّا تَرتَىبُوا إِلَّا أَن تَكُونَِجَارًَحَاضِرًَن تُدِيرُونَهَبَينَكُم فَلَيسَ عَلَيكُم جُنَا حُم أَلنَا تَكتُبُوهَا وَأَشهِدُوا إِذَا تَبَى يَعتُم وَلَا يُرَارَّكَاتِبُ وَلَا شَهِدِ وَإِن تَفعَلُوا فَإِنَّهُفُسُوقُمبِكُم وَاتَّقُاللَّهُ وَيُعَلِّمُكُمُ اللَّهُ وَاللَّهُ بِكُلِّ شَيءٍ عَلِيَ']\n"
     ]
    }
   ],
   "source": [
    "data_dir = './validation_wav2/'\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "paths2audio_files = [os.path.join(data_dir, 'afasy.wav') ] #أُولَئِكَ عَلَى هُدًى مِنْ رَبِّهِمْ وَأُولَئِكَ هُمُ الْمُفْلِحُونَ \n",
    "print(first_asr_model.transcribe(paths2audio_files=paths2audio_files,\n",
    "                                 batch_size=1))                 \n",
    "\n",
    "paths2audio_files = [os.path.join(data_dir, 'sample_23474.wav') ] ## الله الصمد\n",
    "print(first_asr_model.transcribe(paths2audio_files=paths2audio_files,\n",
    "                                 batch_size=1))  \n",
    "\n",
    "paths2audio_files = [os.path.join(data_dir, 'audio_25890.wav') ]# وَلَقَدْ آتَيْنَا دَاوُودَ وَسُلَيْمَانَ عِلْمًا ۖ وَقَالَا الْحَمْدُ لِلَّهِ الَّذِي فَضَّلَنَا عَلَىٰ كَثِيرٍ مِّنْ عِبَادِهِ الْمُؤْمِنِينَ\n",
    "print(first_asr_model.transcribe(paths2audio_files=paths2audio_files,\n",
    "                                 batch_size=1)) \n",
    "\n",
    "paths2audio_files = [os.path.join(data_dir, 'sample_7547.wav') ] #  فَبِأَيِّ آلَاءِ رَبِّكُمَا تُكَذِّبَانِ\n",
    "print(first_asr_model.transcribe(paths2audio_files=paths2audio_files,\n",
    "                                 batch_size=1)) \n",
    "\n",
    "paths2audio_files = [os.path.join(data_dir, 'long_verse.wav') ] \n",
    "print(first_asr_model.transcribe(paths2audio_files=paths2audio_files,\n",
    "                                 batch_size=1)) \n",
    "#يَا أَيُّهَا الَّذِينَ آمَنُوا اذْكُرُوا نِعْمَةَ اللَّهِ عَلَيْكُمْ إِذْ جَاءَتْكُمْ جُنُودٌ فَأَرْسَلْنَا عَلَيْهِمْ رِيحًا وَجُنُودًا لَّمْ تَرَوْهَا ۚ وَكَانَ اللَّهُ بِمَا تَعْمَلُونَ بَصِيرًا\n",
    "\n",
    "\n",
    "paths2audio_files = [os.path.join(data_dir, 'ayetEldayn.wav') ] \n",
    "print(first_asr_model.transcribe(paths2audio_files=paths2audio_files,\n",
    "                                 batch_size=1)) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec1474804d24b5bacdfdae0c29a5fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['إِنَّ الَّذِينَ آمَنُوا وَعَمِلُوا الصَّالِحَاتِ لَهُم جَنَّاتُن تَ جرِي مِن تَحتِهَا ل أَنهَارِ ذَلِكَ الفَوزُو الكَ بِلِهِرِ']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3d31357ea74d528d4253bfff7430b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['بَلهُوَ قُرآنٌ مَجِيدٌ']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970d87fa0ae94a459f8ca50edefcf595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['قُل هُوَ اللَّهُ أَحَدُ']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ac94920fb140f7ad6a002fa9b1b9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['وَأَقِيمُوا الصَّلَاَوَآتُوا الزَّكَاتَ وَأَطِيعُو الرَّسُونَ لَعَلَّكُم تُرحًمُونَ']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1abaee711b34c5d9bc97f96cf6e862d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['والرَّحمَنُ عَلَى لعَرشِ استَوَى']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bac022be98493fa5fe45dd2f67c292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['إِنَّا أَعطَينَاكَ الكَوثَر']\n"
     ]
    }
   ],
   "source": [
    "data_dir = './validation_wav2/'\n",
    "\n",
    "\n",
    "paths2audio_files = [os.path.join(data_dir, 'sample_8279.wav') ]  \n",
    "print(first_asr_model.transcribe(paths2audio_files=paths2audio_files,\n",
    "                                 batch_size=1))\n",
    "\n",
    "\n",
    "paths2audio_files = [os.path.join(data_dir, 'sample_8280.wav') ]  \n",
    "print(first_asr_model.transcribe(paths2audio_files=paths2audio_files,\n",
    "                                 batch_size=1))\n",
    "\n",
    "paths2audio_files = [os.path.join(data_dir, 'sample_8312.wav') ]  \n",
    "print(first_asr_model.transcribe(paths2audio_files=paths2audio_files,\n",
    "                                 batch_size=1))\n",
    "\n",
    "\n",
    "paths2audio_files = [os.path.join(data_dir, 'sample_9774.wav') ]  \n",
    "print(first_asr_model.transcribe(paths2audio_files=paths2audio_files,batch_size=1))\n",
    "\n",
    "\n",
    "\n",
    "paths2audio_files = [os.path.join(data_dir, 'sample_9722.wav') ]  \n",
    "print(first_asr_model.transcribe(paths2audio_files=paths2audio_files,\n",
    "                                 batch_size=1))\n",
    "\n",
    "\n",
    "paths2audio_files = [os.path.join(data_dir, 'sample_9494.wav') ]  \n",
    "print(first_asr_model.transcribe(paths2audio_files=paths2audio_files,\n",
    "                                 batch_size=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
