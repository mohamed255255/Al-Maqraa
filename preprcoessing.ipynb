{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import librosa\n",
    "from IPython.display import Audio\n",
    "from pydub import AudioSegment\n",
    "import wave\n",
    "import pyaudio\n",
    "import IPython.display as ipd\n",
    "import pyarrow.parquet as pq\n",
    "import soundfile as sf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1#Enhance the power of signal over noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preemphasis(signal, preemphasis_coeff=0.97):\n",
    "    return np.append(signal[0], signal[1:] - preemphasis_coeff * signal[:-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2# Cut Silence at the begenning and at the end only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# merge short pauses with voiced segments\n",
    "def merge_segments(intervals, min_silence_duration=0.5, sample_rate=None):\n",
    "    merged_intervals = []\n",
    "    prev_end = None\n",
    "    for start, end in intervals:\n",
    "        if prev_end is None:\n",
    "            prev_end = end\n",
    "            merged_intervals.append((start, end))\n",
    "        else:\n",
    "            silence_duration = (start - prev_end) / sample_rate\n",
    "            if silence_duration < min_silence_duration:\n",
    "\n",
    "                merged_intervals[-1] = (merged_intervals[-1][0], end)\n",
    "            else:\n",
    "                merged_intervals.append((start, end))\n",
    "            prev_end = end\n",
    "    return merged_intervals\n",
    "\n",
    "def remove_silence(audio, sample_rate, top_db=30, min_silence_duration=0.5):\n",
    "    non_silent_intervals = librosa.effects.split(audio, top_db=top_db)\n",
    "\n",
    "    merged_intervals = merge_segments(non_silent_intervals, min_silence_duration, sample_rate)\n",
    "\n",
    "    # Extract voiced segments\n",
    "    segments = [audio[start:end] for start, end in merged_intervals]\n",
    "\n",
    "    processed_audio = np.concatenate(segments)\n",
    "\n",
    "    return processed_audio.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3# Removing the echo noise in the background using spectral substraction technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_subtraction(audio_data, alpha=2.0):\n",
    "\n",
    "    stft_matrix = librosa.stft(audio_data)\n",
    "\n",
    "    magnitude = np.abs(stft_matrix)\n",
    "\n",
    "    phase = np.angle(stft_matrix)\n",
    "\n",
    "    noise_spectrum = np.median(magnitude, axis=1)\n",
    "\n",
    "    # Apply Spectral Subtraction\n",
    "    clean_magnitude = np.maximum(magnitude - alpha * noise_spectrum[:, np.newaxis], 0)\n",
    "\n",
    "    # Reconstruct clean audio signal\n",
    "    clean_stft = clean_magnitude * np.exp(1j * phase)\n",
    "\n",
    "    clean_audio = librosa.istft(clean_stft) ##Return back to time-domain signal \n",
    "\n",
    "    return clean_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import write\n",
    "\n",
    "def preprocessing(audio_data , sr , row_number):\n",
    "    cleaned_audio = spectral_subtraction(audio_data)\n",
    "    cleaned_audio = preemphasis(cleaned_audio)\n",
    "    cleaned_audio = remove_silence(cleaned_audio,sr)\n",
    "    \n",
    "    output_file = os.path.join('training_wav/', f\"sample_{row_number}.wav\")\n",
    "    write(output_file, sr, cleaned_audio)\n",
    "    return cleaned_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print it once u finish collecting the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training.json', 'w', encoding='utf-8') as f:\n",
    "    for entry in json_data:\n",
    "        json.dump(entry, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sallam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
